
# ğŸ§¬ RNA-FoldNet: A Hybrid Graph-Transformer Model with Energy-Based Refinement for RNA 3D Structure Prediction

**A modular deep learning pipeline for RNA tertiary structure prediction** combining contrastive pretraining, graph-transformer modeling, and denoising diffusion refinement â€” built entirely with **PyTorch** and trained on the **Stanford RNA 3D Folding Dataset**.

> Powered by **GNNs**, **Transformer Attention**, and **DDPM-based denoising**, this architecture bridges sequence and spatial reasoning for high-fidelity RNA 3D structure prediction.

---

## ğŸš€ Key Features

- **Contrastive Pretraining** on RNA structural triplets using Triplet Loss
- **Graph Transformer Architecture** for coarse 3D coordinate prediction
- **Denoising Diffusion Refinement** for atomic-level accuracy
- **Rotationally Invariant Embeddings** to boost geometric robustness
- **Colab-Ready**, GPU-optimized pipeline

---

## ğŸ› ï¸ Tech Stack

### ğŸ“¦ Frameworks & Libraries
- PyTorch Â· PyTorch Geometric Â· HuggingFace Transformers
- NumPy Â· SciPy Â· pandas Â· scikit-learn Â· networkx
- matplotlib Â· seaborn Â· plotly Â· tqdm

### ğŸ§  Modeling
- GCNConv / GATConv + Multi-head Attention
- Contrastive Encoder with CNN/BiLSTM
- DDPM-based Refinement Model
- Losses: Triplet, RMSD, Denoising Loss

---

## ğŸ“Š Visualizations

### 1. **3D Overlay: Ground Truth vs Coarse vs Refined**
![Overlay](overlay_gt_coarse_refined.jpeg)

### 2. **Color-Mapped Structural Predictions**
- Ground Truth  
  ![GT](ground_truth.jpeg)
- Coarse Prediction  
  ![Coarse](coarse_prediction.jpeg)
- Refined Output  
  ![Refined](refined_prediction.jpeg)

### 3. **t-SNE of Contrastive Embeddings**
![tSNE](tsne_embeddings.jpeg)

### 4. **Training Curves**
![Loss](training_loss.jpeg)

### 5. **Sequence Length Distribution**
![LengthDist](length_distribution.jpeg)

### 6. **Diffusion Steps**
![Diffusion](diffusion_steps.jpeg)

### 7. **Pairwise Distance Comparison**
![Distances](pairwise_comparison.jpeg)

---

## ğŸ“ Dataset

- **Source:** [Stanford RNA 3D Folding Dataset (Kaggle)](https://www.kaggle.com/competitions/stanford-rna-3d-folding)
- **Train:** 844 samples
- **Test:** 12 samples
- **Sequence Length:** 3 to 4298 nucleotides

---

## ğŸ“ˆ Performance

| Metric             | Coarse  | Refined |
|--------------------|---------|---------|
| RMSD â†“            | 0.3014  | **0.0692** |
| Pearson Corr â†‘    | 0.9996  | **0.99998** |
| Distance Error â†“  | 0.47    | **0.11**   |

---

### ğŸ§ª Training & Inference

All stages â€” contrastive pretraining, graph-transformer modeling, and diffusion refinement â€” are implemented in a single Jupyter Notebook.

ğŸ“˜ **RNA_Foldnet.ipynb**

```bash
# Step 1: Launch the notebook
Open RNA_Foldnet.ipynb in Google Colab or Jupyter Notebook

# Step 2: Run all cells
Execute sequentially from data loading to final prediction & plots
```

---

## ğŸ“¦ Inference

```python
from model.infer import predict_structure

coords = predict_structure(sequence="GAGCGUCUA...")
```

---

## ğŸ“Œ Authors

- Jyotishman Das  
- Suvadip Chakraborty   
- Denzel Lenshanglen Lupheng 

---

## ğŸ Citation

```
@project{rnafoldnet2025,
  title={RNA-FoldNet: A Hybrid Graph-Transformer Model with Energy-Based Refinement for RNA 3D Structure Prediction},
  author={Das, J. and Chakraborty, S. and Lupheng, D.},
  year={2025},
  note={CSL7590 Deep Learning Project, IIT Jodhpur}
}
```
